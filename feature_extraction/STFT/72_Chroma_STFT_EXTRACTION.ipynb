{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy.stats import skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Study\\Code\\Python\\Sound_Classification_Bee_Qeen_Queenless/audio_dataset/\n",
      "d:\\Study\\Code\\Python\\Sound_Classification_Bee_Qeen_Queenless/Chroma_STFT_npy_dataset/\n"
     ]
    }
   ],
   "source": [
    "PATH = os.getcwd() + '/audio_dataset/'\n",
    "SAVING_PATH = os.getcwd() + '/Chroma_STFT_npy_dataset/'\n",
    "print(PATH)\n",
    "print(SAVING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAV_DIR = [\"train/Queen/\", \"train/Queenless/\", \"test/Queen/\", \"test/Queenless/\", \"val/Queen/\", \"val/Queenless/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_16k_mono(path):\n",
    "    y, sr = librosa.load(path, sr=16000, mono=True)\n",
    "    return y, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft(y, n_fft, hop_length, win_length, window, center=True):\n",
    "    feature = librosa.feature.chroma_stft(y=y, sr=16000, n_fft=n_fft, hop_length=hop_length, win_length=win_length, window=window, center=center)\n",
    "    # print(feature.shape)\n",
    "    feature_mean = np.mean(np.abs(feature).T,axis=0) \n",
    "    feature_std=np.std(np.abs(feature).T,axis=0)\n",
    "    # feature_min=np.min(np.abs(feature).T,axis=0)\n",
    "    # feature_max=np.max(np.abs(feature).T,axis=0)\n",
    "    # feature_skew = skew(np.abs(feature).T,axis=0)\n",
    "    # feature_median = np.median(np.abs(feature).T,axis=0)\n",
    "    # feature = np.hstack((feature_mean,feature_std,feature_min,feature_max,feature_skew,feature_median))\n",
    "    feature = np.hstack((feature_mean,feature_std))\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STFT feature shape:  (72, 1)\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH = os.listdir(PATH+ NAV_DIR[0])[0]\n",
    "y, sr = read_16k_mono(PATH + NAV_DIR[0] + FILE_PATH)\n",
    "feature = stft(y, n_fft=1024, hop_length=None, win_length=None, window = \"hamming\")\n",
    "feature = feature.reshape(feature.shape[0], 1)\n",
    "print(\"STFT feature shape: \", feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- time_frame = (TIME*SR)//HOP_LENGTH\n",
    "- pitch = 12\n",
    "- in stft\n",
    "- frequerency_bin = (win_length//2)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why axis = 1 but still keep 126 columns??**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_extract_stft(path):\n",
    "    data = []\n",
    "    print(\"Extracting data from \" + path)\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(\".wav\"):\n",
    "            y, sr = read_16k_mono(path + file)\n",
    "            feature = stft(y, n_fft=1024, hop_length=None, win_length=None, window = \"hann\")\n",
    "            data.append(feature)\n",
    "    print(f\"Extracted {len(data)} files from {path}\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from d:\\Study\\Code\\Python\\Sound_Classification_Bee_Qeen_Queenless/audio_dataset/train/Queen/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minht\\anaconda3\\envs\\gpu\\lib\\site-packages\\librosa\\core\\pitch.py:102: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 7000 files from d:\\Study\\Code\\Python\\Sound_Classification_Bee_Qeen_Queenless/audio_dataset/train/Queen/\n",
      "Extracting data from d:\\Study\\Code\\Python\\Sound_Classification_Bee_Qeen_Queenless/audio_dataset/train/Queenless/\n",
      "Extracted 7000 files from d:\\Study\\Code\\Python\\Sound_Classification_Bee_Qeen_Queenless/audio_dataset/train/Queenless/\n",
      "Extracting data from d:\\Study\\Code\\Python\\Sound_Classification_Bee_Qeen_Queenless/audio_dataset/test/Queen/\n",
      "Extracted 2000 files from d:\\Study\\Code\\Python\\Sound_Classification_Bee_Qeen_Queenless/audio_dataset/test/Queen/\n",
      "Extracting data from d:\\Study\\Code\\Python\\Sound_Classification_Bee_Qeen_Queenless/audio_dataset/test/Queenless/\n",
      "Extracted 2000 files from d:\\Study\\Code\\Python\\Sound_Classification_Bee_Qeen_Queenless/audio_dataset/test/Queenless/\n",
      "Extracting data from d:\\Study\\Code\\Python\\Sound_Classification_Bee_Qeen_Queenless/audio_dataset/val/Queen/\n",
      "Extracted 1000 files from d:\\Study\\Code\\Python\\Sound_Classification_Bee_Qeen_Queenless/audio_dataset/val/Queen/\n",
      "Extracting data from d:\\Study\\Code\\Python\\Sound_Classification_Bee_Qeen_Queenless/audio_dataset/val/Queenless/\n",
      "Extracted 1000 files from d:\\Study\\Code\\Python\\Sound_Classification_Bee_Qeen_Queenless/audio_dataset/val/Queenless/\n",
      "Extract time: 2.17 minutes\n"
     ]
    }
   ],
   "source": [
    "DATA = []\n",
    "time0 = datetime.now()\n",
    "for SUB_PATH in NAV_DIR:\n",
    "    sub_data = data_extract_stft(PATH + SUB_PATH)\n",
    "    DATA.append(sub_data)\n",
    "time1 = datetime.now()\n",
    "extract_time = (time1 - time0).seconds / 60\n",
    "print('Extract time: %.2f minutes' % extract_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 72)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(DATA[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Queen_Choma_STFT.npy\n",
      "Saving Queenless_Choma_STFT.npy\n",
      "Saving Queen_Choma_STFT.npy\n",
      "Saving Queenless_Choma_STFT.npy\n",
      "Saving Queen_Choma_STFT.npy\n",
      "Saving Queenless_Choma_STFT.npy\n"
     ]
    }
   ],
   "source": [
    "for index in range(len(DATA)):\n",
    "    np.save(SAVING_PATH + NAV_DIR[index] + NAV_DIR[index].split('/')[-2] + '_Choma_STFT.npy', np.array(DATA[index]))\n",
    "    print('Saving ' + NAV_DIR[index].split('/')[-2] + '_Choma_STFT.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
